{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "644876bb-4120-4ad3-9db5-efbcdbc1acc6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b401669-6e3b-40e3-a71d-8a9a4ede5371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliothèques importées avec succès !\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import face_utils\n",
    "import os\n",
    "import time\n",
    "from IPython.display import display, Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configuration de matplotlib\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 5)\n",
    "\n",
    "print(\"Bibliothèques importées avec succès !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c9e88-7631-4741-8d54-9169656283d6",
   "metadata": {},
   "source": [
    "# Paramètres d'enregistrement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d0e3e0-a172-4f5f-ab06-dcd4059aa81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossiers créés : ../data/video_recordings\\oui et ../data/lip_frames\\oui\n",
      "Dossiers créés : ../data/video_recordings\\non et ../data/lip_frames\\non\n",
      "Dossiers créés : ../data/video_recordings\\un et ../data/lip_frames\\un\n",
      "Dossiers créés : ../data/video_recordings\\deux et ../data/lip_frames\\deux\n",
      "\n",
      "Configuration terminée !\n"
     ]
    }
   ],
   "source": [
    "frame_rate = 30  # Images par seconde\n",
    "duration = 1     # Durée d'enregistrement en secondes (1 seconde suffit pour les mots courts)\n",
    "width = 640      # Largeur de la vidéo\n",
    "height = 480     # Hauteur de la vidéo\n",
    "\n",
    "# Mots cibles à enregistrer\n",
    "target_words = [\"oui\", \"non\", \"un\", \"deux\"]\n",
    "\n",
    "# Nombre d'exemples par mot\n",
    "examples_per_word = 10\n",
    "\n",
    "# Chemins pour sauvegarder les fichiers\n",
    "video_dir = \"../data/video_recordings\"\n",
    "lip_dir = \"../data/lip_frames\"\n",
    "# Vérifier que les dossiers existent\n",
    "for word in target_words:\n",
    "    word_video_dir = os.path.join(video_dir, word)\n",
    "    word_lip_dir = os.path.join(lip_dir, word)\n",
    "    os.makedirs(word_video_dir, exist_ok=True)\n",
    "    os.makedirs(word_lip_dir, exist_ok=True)\n",
    "    print(f\"Dossiers créés : {word_video_dir} et {word_lip_dir}\")\n",
    "\n",
    "print(\"\\nConfiguration terminée !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d0ad2-e5e0-4632-ac50-6853c38cd268",
   "metadata": {},
   "source": [
    "# Initialisation du détecteur de visage et du prédicteur de points de repère\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c24b0c81-7685-4081-9f55-28a09e4c719f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Détecteur de points de repère chargé !\n"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor_path = \"../models/shape_predictor_68_face_landmarks.dat\"\n",
    "if os.path.exists(predictor_path):\n",
    "    predictor = dlib.shape_predictor(predictor_path)\n",
    "    print(\"Détecteur de points de repère chargé !\")\n",
    "else:\n",
    "    print(f\"ATTENTION: Le fichier {predictor_path} n'a pas été trouvé.\")\n",
    "    print(\"Téléchargez-le depuis http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "    print(\"Puis décompressez-le et placez-le dans le dossier 'models'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5daa05c-fbae-4093-a85e-975d55b4e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video(duration=duration, frame_rate=frame_rate, width=width, height=height):\n",
    "    \"\"\"\n",
    "    Enregistre une vidéo avec la webcam et retourne la liste des images.\n",
    "    \"\"\"\n",
    "    print(f\"Enregistrement de {duration} secondes...\")\n",
    "    \n",
    "    # Initialisation de la webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    \n",
    "    # Countdown\n",
    "    for i in range(3, 0, -1):\n",
    "        print(f\"{i}...\")\n",
    "        time.sleep(0.5)\n",
    "        \n",
    "    print(\"Parlez maintenant !\")\n",
    "    \n",
    "    frames = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < duration:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Convertir BGR en RGB pour l'affichage avec matplotlib\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame_rgb)\n",
    "        \n",
    "        # Afficher l'image en temps réel\n",
    "        cv2.imshow('Recording', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    # Libérer la webcam et fermer les fenêtres\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"Enregistrement terminé !\")\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e33569d-c912-4a06-a74e-8b27f5151ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lip_region(frame):\n",
    "    \"\"\"\n",
    "    Extrait la région des lèvres d'une image.\n",
    "    \"\"\"\n",
    "    # Convertir en niveaux de gris pour la détection\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Détecter les visages\n",
    "    faces = detector(gray, 0)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Prendre le premier visage détecté\n",
    "    face = faces[0]\n",
    "    \n",
    "    # Prédire les points de repère\n",
    "    shape = predictor(gray, face)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "    # Les points des lèvres sont les points 48-68 dans le modèle à 68 points\n",
    "    lips_points = shape[48:68]\n",
    "    \n",
    "    # Calculer le rectangle englobant pour les lèvres\n",
    "    x, y = lips_points.min(axis=0)\n",
    "    w, h = lips_points.max(axis=0) - lips_points.min(axis=0)\n",
    "    \n",
    "    # Ajouter une marge\n",
    "    margin = 10\n",
    "    x = max(0, x - margin)\n",
    "    y = max(0, y - margin)\n",
    "    w = min(frame.shape[1] - x, w + 2 * margin)\n",
    "    h = min(frame.shape[0] - y, h + 2 * margin)\n",
    "    \n",
    "    # Extraire la région des lèvres\n",
    "    lip_region = frame[y:y+h, x:x+w]\n",
    "    \n",
    "    return lip_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ccc3dc-7633-41ee-b3ea-6100086bc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_recording(frames):\n",
    "    \"\"\"\n",
    "    Affiche un aperçu de l'enregistrement et des régions des lèvres extraites.\n",
    "    \"\"\"\n",
    "    if not frames:\n",
    "        print(\"Aucune image à afficher !\")\n",
    "        return\n",
    "    \n",
    "    # Extraire les régions des lèvres\n",
    "    lip_regions = []\n",
    "    for frame in frames:\n",
    "        lip_region = extract_lip_region(frame)\n",
    "        if lip_region is not None:\n",
    "            lip_regions.append(lip_region)\n",
    "    \n",
    "    # Sélectionner quelques images à afficher\n",
    "    num_display = min(4, len(frames))\n",
    "    if num_display > 0:\n",
    "        display_indices = np.linspace(0, len(frames)-1, num_display, dtype=int)\n",
    "        \n",
    "        plt.figure(figsize=(16, 8))\n",
    "        \n",
    "        for i, idx in enumerate(display_indices):\n",
    "            frame = frames[idx]\n",
    "            \n",
    "            # Afficher l'image complète\n",
    "            plt.subplot(2, num_display, i+1)\n",
    "            plt.imshow(frame)\n",
    "            plt.title(f'Image {idx+1}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Afficher la région des lèvres si disponible\n",
    "            plt.subplot(2, num_display, i+1+num_display)\n",
    "            if idx < len(lip_regions):\n",
    "                lip_region = lip_regions[idx]\n",
    "                plt.imshow(lip_region)\n",
    "                plt.title(f'Lèvres {idx+1}')\n",
    "            else:\n",
    "                plt.text(0.5, 0.5, 'Lèvres non détectées', ha='center', va='center')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Afficher les statistiques\n",
    "    if lip_regions:\n",
    "        print(f\"Nombre d'images avec lèvres détectées : {len(lip_regions)}/{len(frames)}\")\n",
    "        print(f\"Taille moyenne de la région des lèvres : {np.mean([r.shape[0] for r in lip_regions]):.1f} x {np.mean([r.shape[1] for r in lip_regions]):.1f} pixels\")\n",
    "    else:\n",
    "        print(\"Aucune lèvre détectée dans les images!\")\n",
    "    \n",
    "    return lip_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63ee0f5d-df82-4b3c-a277-75acde99fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_video_and_lips(frames, word, example_index):\n",
    "    \"\"\"\n",
    "    Sauvegarde la vidéo et les régions des lèvres.\n",
    "    \"\"\"\n",
    "    if not frames:\n",
    "        print(\"Aucune image à sauvegarder !\")\n",
    "        return [], []\n",
    "    \n",
    "    # Chemins pour la vidéo\n",
    "    video_filename = f\"{word}_{example_index:02d}.mp4\"\n",
    "    video_path = os.path.join(video_dir, word, video_filename)\n",
    "    \n",
    "    # Taille de la première image\n",
    "    h, w = frames[0].shape[:2]\n",
    "    \n",
    "    # Créer l'objet VideoWriter\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(video_path, fourcc, frame_rate, (w, h))\n",
    "    \n",
    "    # Extraire et sauvegarder les régions des lèvres\n",
    "    lip_paths = []\n",
    "    \n",
    "    for i, frame in enumerate(frames):\n",
    "        # Convertir RGB en BGR pour OpenCV\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        out.write(frame_bgr)\n",
    "        \n",
    "        # Extraire et sauvegarder la région des lèvres\n",
    "        lip_region = extract_lip_region(frame)\n",
    "        if lip_region is not None:\n",
    "            lip_filename = f\"{word}_{example_index:02d}_{i+1:03d}.png\"\n",
    "            lip_path = os.path.join(lip_dir, word, lip_filename)\n",
    "            cv2.imwrite(lip_path, cv2.cvtColor(lip_region, cv2.COLOR_RGB2BGR))\n",
    "            lip_paths.append(lip_path)\n",
    "    \n",
    "    # Libérer les ressources\n",
    "    out.release()\n",
    "    \n",
    "    print(f\"Vidéo sauvegardée : {video_path}\")\n",
    "    print(f\"{len(lip_paths)} images de lèvres sauvegardées dans {os.path.join(lip_dir, word)}\")\n",
    "    \n",
    "    return video_path, lip_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4876142-40bf-44e6-bd50-815ffd2156a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_examples_for_word(word, num_examples=examples_per_word):\n",
    "    \"\"\"\n",
    "    Collecte plusieurs exemples vidéo pour un mot donné.\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Collecte d'exemples pour le mot '{word}' ===\\n\")\n",
    "    \n",
    "    video_paths = []\n",
    "    all_lip_paths = []\n",
    "    \n",
    "    for i in range(1, num_examples + 1):\n",
    "        print(f\"\\nExemple {i}/{num_examples} pour '{word}'\")\n",
    "        \n",
    "        # Enregistrement\n",
    "        frames = record_video()\n",
    "        \n",
    "        # Visualisation\n",
    "        lip_regions = visualize_recording(frames)\n",
    "        \n",
    "        # Demander à l'utilisateur si l'enregistrement est bon\n",
    "        valid = input(\"Cet enregistrement est-il bon ? (o/n) : \").lower()\n",
    "        \n",
    "        if valid == 'o':\n",
    "            # Sauvegarde\n",
    "            video_path, lip_paths = save_video_and_lips(frames, word, i)\n",
    "            video_paths.append(video_path)\n",
    "            all_lip_paths.extend(lip_paths)\n",
    "            print(f\"Exemple {i} sauvegardé\")\n",
    "        else:\n",
    "            print(\"Enregistrement ignoré. Réessayons.\")\n",
    "            i -= 1  # Réessayer\n",
    "    \n",
    "    print(f\"\\nCollecte terminée pour le mot '{word}' ! {len(video_paths)} exemples sauvegardés.\")\n",
    "    return video_paths, all_lip_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1278e-1f4b-4d61-9bc1-20a4b0abff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour collecter des exemples pour tous les mots\n",
    "all_video_paths = {}\n",
    "all_lip_paths = {}\n",
    "\n",
    "for word in target_words:\n",
    "    video_paths, lip_paths = collect_examples_for_word(word)\n",
    "    all_video_paths[word] = video_paths\n",
    "    all_lip_paths[word] = lip_paths\n",
    "    \n",
    "print(\"\\nCollecte terminée pour tous les mots !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa609e19-1d6b-4e93-b0cc-60c29fbae07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data_collection():\n",
    "    \"\"\"\n",
    "    Vérifie les données collectées et affiche un résumé.\n",
    "    \"\"\"\n",
    "    print(\"=== Résumé des données collectées ===\\n\")\n",
    "    \n",
    "    total_videos = 0\n",
    "    total_lip_frames = 0\n",
    "    \n",
    "    for word in target_words:\n",
    "        word_video_dir = os.path.join(video_dir, word)\n",
    "        word_lip_dir = os.path.join(lip_dir, word)\n",
    "        \n",
    "        videos = [f for f in os.listdir(word_video_dir) if f.endswith('.mp4')]\n",
    "        lip_frames = [f for f in os.listdir(word_lip_dir) if f.endswith('.png')]\n",
    "        \n",
    "        print(f\"Mot '{word}' : {len(videos)} vidéos, {len(lip_frames)} images de lèvres\")\n",
    "        \n",
    "        total_videos += len(videos)\n",
    "        total_lip_frames += len(lip_frames)\n",
    "        \n",
    "        # Afficher quelques statistiques sur les images de lèvres\n",
    "        if lip_frames:\n",
    "            lip_sizes = []\n",
    "            for lip_file in lip_frames[:5]:  # Limite à 5 fichiers pour économiser du temps\n",
    "                lip_path = os.path.join(word_lip_dir, lip_file)\n",
    "                lip_img = cv2.imread(lip_path)\n",
    "                lip_sizes.append((lip_img.shape[0], lip_img.shape[1]))\n",
    "            \n",
    "            if lip_sizes:\n",
    "                avg_height = np.mean([s[0] for s in lip_sizes])\n",
    "                avg_width = np.mean([s[1] for s in lip_sizes])\n",
    "                print(f\"  Taille moyenne des images de lèvres : {avg_height:.1f} x {avg_width:.1f} pixels\")\n",
    "    \n",
    "    print(f\"\\nTotal : {total_videos} vidéos, {total_lip_frames} images de lèvres\")\n",
    "    \n",
    "    return total_videos, total_lip_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db982bc6-7f8a-4757-801b-0a069af21a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_collection()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
